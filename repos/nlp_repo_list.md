# NLP 레포 추천

## 선정 기준
- 데이터 전처리 파이프라인이 명확할 것
- 학습/평가 지표가 정리되어 있을 것
- 모델 구조를 바꿔도 실행 흐름이 안정적일 것

## 주의 사항
- 해당 레포는 추천 자료일 뿐, 반드시 이 중에서 선택해야 하는 것은 아닙니다. 다른 레포를 찾아보거나, 논문 구현 레포를 직접 찾아보는 것도 좋은 방법입니다.
- 운영진은 추천 레포 리스트만 제공하며, 레포 선정과 실험 과정에서 발생하는 문제에 대해서는 지원하지 않습니다. 팀원들과 협력하여 문제를 해결해 나가는 것도 중요한 과정입니다.

## 후보 레포 1 : LLaMA-Factory
- 링크: https://github.com/hiyouga/LLaMA-Factory
- 핵심 내용
    - LLM의 효율적인 학습을 위한 통합 툴
    - LoRA, QLoRA 등 경량화 학습 기법과 다양한 데이터셋 템플릿 지원
    - CLI와 WebUI를 모두 지원하여 실험 환경 구축 용이
- 장점
    - 허깅페이스에 올라온 거의 모든 최신 모델을 Config 수정만으로 갈아끼우며 실험할 수 있음
    - dataset_info.json을 통해 커스텀 데이터를 어떻게 포맷팅해야 하는지 명확히 제시해줌
    - 단순 Loss뿐만 아니라 BLEU, ROUGE 등 생성 모델 평가 지표가 자동으로 계산되어, 모델 개선 효과를 객관적으로 비교하기 좋음
- 주의사항
    - 아무리 경량화를 해도 GPU VRAM(최소 16GB 이상 권장)이 꽤 필요하므로, Colab Pro나 서버 환경이 필수적
    - 학습률 스케줄러, 워밍업, 배치 사이즈 등 하이퍼파라미터가 매우 많아 초기 설정에 대한 이해가 필요할 수 있음

## 후보 레포 2 : Sentence-Transformers (SBERT)
- 링크: https://github.com/UKPLab/sentence-transformers
- 핵심 내용
    - 문장 임베딩 모델을 학습하고 평가하는 프레임워크.
    - Contrastive Learning을 통해 두 문장의 유사도를 학습시키는 구조가 핵심
- 장점
    - InputExample → DataLoader → Loss → Evaluator로 이어지는 객체지향적 설계가 매우 깔끔하여, NLP 모델 학습의 전체적인 흐름을 이해하기에 좋음
    - Semantic Textual Similarity 벤치마크 점수가 직관적으로 나와, 내가 튜닝한 모델이 얼마나 좋아졌는지 바로 확인 가능
    - 다양한 손실 함수를 바꿔가며 실험해볼 수 있어, 모델 개선을 위한 아이디어를 적용해보기 좋음
- 주의사항
    - 학습을 위해선 (문장 A, 문장 B, 유사도 점수) 형태의 데이터셋 구축이 필수적인데, 이 데이터를 만드는 과정이 까다로울 수 있음
    - 기본 예제는 영어 중심이므로, klue/roberta-base 같은 한국어 Pre-trained 모델로 교체하는 과정이 필요할 수 있음

## 후보 레포 3 : ratsgo/nlpbook (Do it! BERT와 GPT로 배우는 자연어 처리)
- 링크: https://github.com/ratsgo/nlpbook
- 핵심 내용
    - 한국어 자연어 처리 입문자에게 친절한 튜토리얼과 코드 예제를 제공하는 레포
    - BERT, GPT 등 대표적인 NLP 모델의 기본 구조와 학습 과정을 단계별로 설명
    - Hugging Face Transformers와 PyTorch Lightning을 결합하여, 상용 수준의 코드 구조를 학습할 수 있도록 설계
- 장점
    - 저자가 한국인이며, 코드와 연동되는 상세한 설명이 웹사이트에 공개되어 있음
    - 구조가 매우 탄탄하여, 데이터를 넣었을 때 에러가 날 확률이 가장 적고 디버깅이 쉬운 편
    - LightningDataModule과 LightningModule을 분리하여 설계하는 법을 배울 수 있어, 코딩 실력 향상에 큰 도움이 됨
- 주의사항
    - 2-3년 전 기준으로 작성된 부분이 있어, 최신 transformers나 pytorch-lightning 버전과 호환성 이슈가 발생할 수 있음 (오히려 이걸 해결하며 배우는게 많을 수도? 럭키비키)
    - 프레임워크가 강제하는 구조가 있어, 밑바닥부터 짜고 싶은 학생에게는 다소 답답할 수 있음